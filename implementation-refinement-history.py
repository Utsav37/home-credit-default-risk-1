from feature_selection import *
from library.datasets import Datasets
from transformations import df_cols_for_apps, df_cols_for_tree

datasets = Datasets(
    path="input/*.csv",
    target="TARGET",
    id_matcher="SK.*ID.*",
    exclude_paths=['input/application_test.csv', 'input/HomeCredit_columns_description.csv'],
)

# show default params with 1 file
with timer("load tree df and cols"):
    df_apps, cols_apps = df_cols_for_apps(nrows=ROWS)

with timer('train with just application_train.csv derived features'):
    target, predictions = kaggle_train_to_submit(df_apps, cols_apps, get_lightgbm_with_default_parameters, to_files=False)

# with all files with default
with timer("load tree df and cols"):  # full load takes ~30 minutes
    df_full, cols_full = df_cols_for_tree(datasets.tree, nrows=ROWS)

with timer('train with all created features'):
    print("Below is the Initial Solution")
    target, predictions = kaggle_train_to_submit(df_full, cols_full, get_lightgbm_with_default_parameters, to_files=False)

# Feature Selection
col_effect = dict_from_csv('meta/col_effect_full_comma.csv')  # This file was generated by populate_col_effect.py
best_cols = [c for c, r in col_effect.items() if r > 0.5 and c in df_full.columns]
best_variants = get_best_variants(best_cols)

with timer('train with feature selection'):
    target, predictions = kaggle_train_to_submit(df_full, best_variants, get_lightgbm_with_default_parameters, to_files=False)

# Hyper Parameter Tuned Model. Tuning was done in hyperparameter-tuning.py
with timer('train with feature selection'):
    print("Below is the Final Refinement")
    target, predictions = kaggle_train_to_submit(df_full, cols_full, get_lightgbm_with_tuned_hyperparameters, to_files=True)
